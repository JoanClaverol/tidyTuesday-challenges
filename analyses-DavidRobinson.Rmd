---
title: "TidyTuesday anlyses from David Robinson"
output: 
  html_document: 
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE,
                      cache = TRUE)
```

## Coffee ratings 

```{r}
# libraries
library(tidytuesdayR)
library(tidyverse)

# set plot theme
theme_set(theme_light())

# load data
coffee <- tt_load("2020-07-07")
coffee_ratings <- coffee$coffee_ratings %>%
  mutate(coffee_id = row_number()) %>%
  filter(total_cup_points > 0)
```

```{r}
coffee_ratings %>%
  count(species, sort = TRUE) # sort

# focus on variety, filter out any of it is missing
coffee_lumped <- coffee_ratings %>%
  filter(!is.na(variety)) %>%
  mutate(variety = fct_lump(variety, 12), # select the top 12 factors
         sort = TRUE)


coffee_lumped %>%
  mutate(
    variety = fct_reorder(
      variety, total_cup_points
      ) # reorder factors in relation to the total cup points
    ) %>% 
  ggplot(aes(total_cup_points, variety)) +
    geom_boxplot()


coffee_lumped %>%
  ggplot(aes(total_cup_points, fill = variety)) +
    geom_histogram(binwidth = 1) +
    facet_wrap(~ variety, scale = "free_y") + # adapt y axis to each variety
    theme(legend.position = "none")
```

```{r}

coffee_ratings %>%
  summarize(
    across(
      everything(), ~ mean(!is.na(.))
      )
    ) %>% 
  gather()

coffee_ratings %>%
  count(producer, sort = TRUE)
coffee_ratings %>%
  count(company, sort = TRUE)
coffee_ratings %>%
  count(color, sort = TRUE)


coffee_ratings %>%
  count(country = fct_lump(country_of_origin, 12), sort = TRUE) %>%
  filter(!is.na(country)) %>%
  mutate(country = fct_reorder(country, n)) %>%
  ggplot(aes(n, country)) +
  geom_col()


coffee_ratings %>%
  filter(!is.na(country_of_origin)) %>%
  mutate(country = fct_lump(country_of_origin, 12),
         country = fct_reorder(country, total_cup_points)) %>%
  ggplot(aes(total_cup_points, country)) +
  geom_boxplot()
```

Interesting dimensions:

* Country
* Variety
* Company??

```{r}
library(ggridges)
coffee_metrics <- coffee_ratings %>%
  select(coffee_id, total_cup_points, variety, company,
         country_of_origin,
         altitude_mean_meters,
         aroma:moisture) %>%
  pivot_longer(aroma:cupper_points, names_to = "metric", values_to = "value")
coffee_metrics %>%
  mutate(metric = fct_reorder(metric, value)) %>%
  ggplot(aes(value, metric)) +
  geom_density_ridges() # geom_density for categorical variables in a dataset
coffee_metrics %>%
  group_by(metric) %>%
  summarize(average = mean(value),
            sd = sd(value)) %>%
  arrange(desc(average))
```

```{r}
library(widyr) # finds correlation into a messy dataset
library(ggraph) # show network plot to find out clusters
library(igraph)
library(tidytext)
correlations <- coffee_metrics %>% 
  # do not understand that step
  pairwise_cor(item = metric, feature = coffee_id, value = value, sort = TRUE)


correlations %>%
  head(50) %>%
  # show clusters between correlated variables
  graph_from_data_frame() %>% 
  ggraph() +
    geom_edge_link(aes(edge_alpha = correlation)) +
    geom_node_point() +
    geom_node_text(aes(label = name), repel = TRUE)
```


```{r}
# time to apply a pca
coffee_metrics %>%
  filter(!metric %in% c("sweetness", "clean_cup", "uniformity")) %>%
  group_by(metric) %>%
  mutate(centered = value - mean(value)) %>% # center the values
  ungroup() %>%
  widely_svd(item = metric, feature = coffee_id, value = value) %>%
  filter(between(dimension, 2, 5)) %>%
  mutate(metric = reorder_within(metric, value, dimension)) %>%
  ggplot(aes(value, metric)) +
    geom_col() +
    scale_y_reordered() +
    facet_wrap(~ dimension, scales = "free_y")
```

```{r}
coffee_ratings %>%
  filter(altitude_mean_meters < 10000,
         altitude != 1) %>%
  mutate(altitude_mean_meters = pmin(altitude_mean_meters, 3000)) %>%
  ggplot(aes(altitude_mean_meters, total_cup_points)) +
    geom_point() +
    geom_smooth(method = "lm")
```


```{r}
coffee_metrics %>%
  filter(altitude_mean_meters < 10000) %>%
  mutate(altitude_mean_meters = pmin(altitude_mean_meters, 3000)) %>%
  mutate(km = altitude_mean_meters / 1000) %>%
  group_by(metric) %>%
  summarize(correlation = cor(altitude_mean_meters, value),
            model = list(lm(value ~ km))) %>%
  mutate(tidied = map(model, broom::tidy, conf.int = TRUE)) %>%
  unnest(tidied) %>%
  filter(term == "km") %>%
  ungroup() %>%
  mutate(metric = fct_reorder(metric, estimate)) %>%
  ggplot(aes(estimate, metric, color = p.value < .05)) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = .1) +
  labs(y = "Evaluation of coffee",
       x = "Each kilometer of altitude contributes this much to score (95% confidence interval)")
```

## Tour de France

```{r}
# libraries
library(tidytuesdayR)
library(tidyverse)
library(lubridate)
# set plot theme
theme_set(theme_light())
```


```{r}
tuesdata <- tidytuesdayR::tt_load('2020-04-07')
# look at the columns on the dataset
# let's analyse the birth winners
tdf_winners <- tuesdata$tdf_winners %>% 
  mutate(year = year(start_date), 
         speed = distance / time_overall)

stage_data <- tuesdata$stage_data
tdf_stages <- tuesdata$tdf_stages %>% 
  janitor::clean_names() %>% # put all the titles lower
  mutate(year = year(date))

# exploring winners data
tdf_winners %>% 
  count(birth_country, sort = TRUE) %>% 
  mutate(birth_country = fct_reorder(birth_country, n)) %>% 
  ggplot(aes(y = birth_country, x = n)) + 
    geom_col() + 
    labs(y = "", 
         title = "What the counties are the most Tour the France winners born in?")

tdf_winners %>% 
  count(winner_name, birth_country, sort = TRUE)
```

What has change over time? This question leads to how is the age disitributed over time? 

```{r}
tdf_winners %>% 
  group_by(decade = 10 * (year %/% 10)) %>% # truncated division to get the decade
  summarise(winner_age = mean(age), 
            winner_height = mean(height, na.rm = TRUE), 
            winner_weight = mean(weight, na.rm = TRUE)) %>% 
  ggplot(aes(x = decade, y = winner_age)) + 
    geom_line() + 
    expand_limits(y = 0)
```

There is no clear relation with age, weight or height over the year in the winners. 

Now he is looking at the time margin: 

```{r}
library(lubridate)
by_decade <- tdf_winners %>% 
  group_by(decade = 10 * (year %/% 10)) %>% # truncated division to get the decade
  summarise(winner_age = mean(age), 
            winner_height = mean(height, na.rm = TRUE), 
            winner_weight = mean(weight, na.rm = TRUE), 
            winner_margin = mean(time_margin, na.rm = TRUE), 
            winner_speed = mean(speed, na.rm = TRUE))

by_decade %>% 
  filter(decade >= 1910) %>% # there is only two data points in 1910 
  ggplot(aes(x = decade, y = winner_margin * 60)) + # transform to minutes
    geom_line() + 
    expand_limits(y = 0) + 
    labs(x = "Decade", 
         y = "Average margin of winner (minutes)", 
         title = "Tour the France has been getting closer")
```

This chart is meaningful. 

NOw let's look at the time of the winner: 

```{r}
by_decade %>%
  ggplot(aes(x = decade, y = winner_speed)) +
    geom_line() + 
    expand_limits(y = 0) + 
    labs(x = "Decade", 
         y = "Average speed of the winner (km/h)", 
         title = "Tour the France winners have been getting faster")
```

They have started to flatter on the paste year, possible doping?. 
TO know more abou it, I would be looking for some variable that affects the speed, like elevation. But they are on present on the dataset. 
So now we know with the winners dataset they are getting faster and there are getting closer (less margin time). 

Other things, average life expectancy of the winners. To do that, we will do a survivial analyses: 

```{r}
library(survival) # very good for medical proposals
library(broom)

surv_model <- tdf_winners %>% 
  distinct(winner_name, .keep_all = TRUE) %>% 
  transmute(winner_name,
            birth_year = year(born), 
            death_year = year(died), 
            dead = as.integer(!is.na(death_year))) %>% 
  mutate(age_at_death = coalesce(death_year, 2020) - birth_year) %>% # They are not death, we are just saying they are alive in 2020
  survival::survfit(Surv(age_at_death, dead) ~ 1, data = .) 

glance(surv_model)
```

Median life expectancy of a Tour of France winner is 77. 

Now let's start some exploration on the stage data: 

```{r}
# I want to join stage data, but I need to prepare them before doing it 
stages_joined <- stage_data %>% 
  extract(col = stage_results_id,
          into = "stage",
          regex = "stage-(.*)") %>%  # extract anything after "stage"
  inner_join(tdf_stages, by = c("year", "stage")) %>%  # I've lost a little bit of data
  mutate(rank = as.integer(rank)) %>% # NA introduced cause of people not finishing the race
 # add_count(year, stage, name = "competitors") # adding competitors by year and stage
  # now I want to get the number of finishers 
  group_by(year, stage) %>% 
  mutate(finishers = sum(!is.na(rank))) %>% 
  ungroup() %>% 
  mutate(percentile = 1 - rank / finishers)

stages_joined %>% 
  filter(stage == "1") %>% 
  group_by(winner_country) %>% 
  summarise(stages = n(), 
            median_percentile = median(percentile, na.rm = TRUE)) %>% 
  arrange(desc(stages))
```

This table tell us that no country does it better than the average at the first stage. 

How can I find the relation between the results at the first stage and how is affecting at the final results?
Does the winner of the first stage predict their final point ranking?

```{r}
total_points <- stages_joined %>% 
  group_by(year, rider) %>% 
  summarise(total_points = sum(points, na.rm = TRUE)) %>% 
  mutate(points_rank = percent_rank(total_points)) %>% 
  ungroup()

stages_joined %>% 
  filter(stage == "1") %>% 
  inner_join(total_points, by = c("year", "rider")) %>% 
  select(year, rider, percentile_first_stage = percentile, 
         points_rank) %>% 
  mutate(first_stage_bin = cut(percentile_first_stage, seq(0, 1, .1))) %>% 
  filter(!is.na(first_stage_bin)) %>% 
  ggplot(aes(y = first_stage_bin, x = points_rank)) + 
    geom_boxplot() + 
    labs(y = "Decile performance in the first stage", 
         x = "Overall points percentile")

```

So yes, there is a relation between your results at the first stage and the final results. 

Now we are going to use a gganimate to show a race: 

```{r}
library(gganimate)

top_10_2017 <- total_points %>% 
  filter(year == max(year)) %>% 
  top_n(10, total_points)

stages_joined %>% 
  filter(year == max(year)) %>% 
  semi_join(top_10_2017, by = "rider") %>% # now I have all the data for the top 10 riders accross all the time
  mutate(stage = as.integer(stage), 
         points = coalesce(points, 0)) %>% 
  group_by(rider) %>% 
  mutate(cumulative_points = cumsum(points)) %>% 
  ungroup() %>% 
  ggplot(aes(cumulative_points, rider, fill = cumulative_points)) + 
    geom_col() + 
    transition_time(stage) + 
    theme(legend.position = "none") + 
    labs(title = "The 2018 Tour France: Stage: {frame_time}", 
         x = "Cumulative points at this stage", 
         y = "") 
```

## The Office 

```{r}
library(tidyverse)
library(tidytuesdayR)
library(schrute)

# set plot theme
theme_set(theme_light())


office_data <- tt_load("2020-03-17")
office_ratings <- office_data$office_ratings  %>%
  mutate(name = str_to_lower(str_remove_all(title, "\\.| \\(Part.*|\\: Part.*")))

office_transcripts <- as_tibble(theoffice) %>% 
  mutate(season = as.integer(season),
         episode = as.integer(episode)) %>%
  mutate(character = str_remove_all(character, '"')) %>%
  mutate(name = str_to_lower(str_remove_all(episode_name, "\\.| \\(Part.*")))
```

```{r}
library(ggrepel)
office_ratings %>%
  group_by(season) %>%
  summarize(avg_rating = mean(imdb_rating)) %>%
  ggplot(aes(season, avg_rating)) +
    geom_line() +
    scale_x_continuous(breaks = 1:9)
```


```{r}
office_ratings %>%
  mutate(title = fct_inorder(title),
         episode_number = row_number()) %>%
  ggplot(aes(episode_number, imdb_rating)) +
    geom_line() +
    geom_smooth() +
    geom_point(aes(color = factor(season), size = total_votes)) +
    geom_text(aes(label = title), check_overlap = TRUE, hjust = 1) +
    expand_limits(x = -10) +
    theme(panel.grid.major.x = element_blank(),
          legend.position = "none") +
    labs(x = "Episode number",
         y = "IMDB Rating",
         title = "Popularity of The Office episodes over time",
         subtitle = "Color represents season, size represents # of ratings")
```

```{r}
office_ratings %>%
  arrange(desc(imdb_rating)) %>%
  mutate(title = paste0(season, ".", episode, " ", title),
         title = fct_reorder(title, imdb_rating)) %>%
  head(20) %>%
  ggplot(aes(title, imdb_rating, color = factor(season), size = total_votes)) +
  geom_point() +
  coord_flip() +
  labs(color = "Season",
       title = "Most popular episodes of The Office")
```

### Transcripts

```{r}
library(tidytext)
blacklist <- c("yeah", "hey", "uh", "gonna")
blacklist_characters <- c("Everyone", "All", "Both", "Guy", "Girl", "Group")
transcript_words <- office_transcripts %>%
  group_by(character) %>%
  filter(n() >= 100,
         n_distinct(episode_name) > 2) %>%
  ungroup() %>%
  select(-text_w_direction) %>%
  unnest_tokens(word, text) %>% 
  anti_join(stop_words, by = "word") %>%
  filter(!word %in% blacklist,
         !character %in% blacklist_characters)
```


```{r}
character_tf_idf <- transcript_words %>%
  add_count(word) %>%
  filter(n >= 20) %>%
  count(word, character) %>%
  # which words are more specific to each character
  bind_tf_idf(word, character, n) %>%
  arrange(desc(tf_idf))
```

```{r}
character_tf_idf %>%
  filter(character %in% c("Dwight", "Jim", "David Wallace", "Darryl", "Jan", "Holly")) %>%
  group_by(character) %>%
  top_n(10, tf_idf) %>%
  ungroup() %>%
  mutate(word = reorder_within(word, tf_idf, character)) %>%
  ggplot(aes(word, tf_idf)) +
    geom_col() +
    coord_flip() +
    scale_x_reordered() +
    facet_wrap(~ character, scales = "free_y") +
    labs(x = "",
         y = "TF-IDF of character-word pairs")
```

```{r}
office_transcripts %>%
  count(character, sort = TRUE) %>%
  filter(character == "Dwight")
```

### Machine learning model

What affects popularity of an episode:

* Season/time
* Director
* Writer
* Lines per character

```{r}
ratings_summarized <- office_ratings %>%
  group_by(name) %>%
  summarize(imdb_rating = mean(imdb_rating))
character_lines_ratings <- office_transcripts %>%
  filter(!character %in% blacklist_characters) %>%
  count(character, name) %>%
  group_by(character) %>%
  filter(sum(n) >= 50,
         n() >= 5) %>%
  inner_join(ratings_summarized, by = "name")
character_lines_ratings %>%
  summarize(avg_rating = mean(imdb_rating),
            nb_episodes = n()) %>%
  arrange(desc(avg_rating))
```



```{r}
director_writer_features <- office_transcripts %>%
  distinct(name, director, writer) %>%
  gather(type, value, director, writer) %>%
  separate_rows(value, sep = ";") %>%
  unite(feature, type, value, sep = ": ") %>%
  group_by(feature) %>%
  filter(n() >= 3) %>%
  mutate(value = 1) %>%
  ungroup()

character_line_features <- character_lines_ratings %>%
  ungroup() %>%
  transmute(name, feature = character, value = log2(n))
season_features = office_ratings %>%
  distinct(name, season) %>%
  transmute(name, feature = paste("season:", season), value = 1)
features <- bind_rows(director_writer_features,
                      character_line_features,
                      season_features) %>%
  semi_join(office_ratings, by = "name") %>%
  semi_join(office_transcripts, by = "name")
```

```{r}
episode_feature_matrix <- features %>%
  cast_sparse(name, feature, value)
ratings <- ratings_summarized$imdb_rating[match(rownames(episode_feature_matrix), ratings_summarized$name)]
```

```{r}
library(glmnet)
library(broom)
mod <- cv.glmnet(episode_feature_matrix, ratings)
plot(mod)
```


```{r}
tidy(mod$glmnet.fit) %>%
  filter(lambda == mod$lambda.min,
         term != "(Intercept)") %>%
  mutate(term = fct_reorder(term, estimate)) %>%
  ggplot(aes(term, estimate, fill = estimate > 0)) +
  geom_col() +
  coord_flip() +
  labs(y = "Estimated effect on the rating of an episode") +
  theme(legend.position = "none")
```

## Wine ratings

```{r}
library(tidyverse)
library(tidytuesdayR)

theme_set(theme_light())

# load and cleaning step
wine_ratings <- tt_load("2019-05-28")$`winemag-data-130k-v2` %>%
  select(-X1) %>%
  # extract 4 digitis which starts with 20, in a new column called year, 
  extract(title, "year", "(20\\d\\d)", convert = TRUE, remove = FALSE) %>%
  mutate(year = ifelse(year < 1900, NA, year)) %>%
  filter(!is.na(price))
```

```{r}
wine_ratings %>%
  count(country, sort = T)
```


```{r}
wine_ratings %>%
  count(designation, sort = T)
```


```{r}
wine_ratings %>%
  count(country, region_1, sort = TRUE)
```


```{r}
wine_ratings %>%
  count(taster_name, sort = TRUE)
```


```{r}
wine_ratings %>%
  filter(!is.na(designation)) %>%
  count(variety, designation, sort = TRUE)
```


```{r}
wine_ratings %>%
  ggplot(aes(year)) +
  geom_histogram()
```


```{r}
wine_ratings %>%
  ggplot(aes(points)) +
  geom_histogram(binwidth = 1)
```


```{r}
wine_ratings %>%
  ggplot(aes(price)) +
  geom_histogram() +
  # us a log scale to see if iti is a normal distribution
  scale_x_log10()
```

```{r}
ggplot(wine_ratings, aes(price, points)) +
  geom_point(alpha = .1) +
  geom_smooth(method = "lm") +
  scale_x_log10()
# predict the points by the price of a wine
summary(lm(points ~ log2(price), wine_ratings))
```

Every time the price doubles, the expected number of points goes up by 2.

```{r}
library(broom)
model <- wine_ratings %>%
  replace_na(list(taster_name = "Missing", country = "Missing")) %>%
  mutate(country = fct_relevel(fct_lump(country, 7), "US"),
         taster_name = fct_relevel(fct_lump(taster_name, 6), "Missing")) %>%
  lm(points ~ log2(price) + country + year + taster_name, data = .)

model %>%
  tidy(conf.int = TRUE) %>%
  filter(term != "(Intercept)") %>%
  mutate(term = str_replace(term, "country", "Country: "),
         term = str_replace(term, "taster_name", "Taster: "),
         term = fct_reorder(term, estimate)) %>%
  ggplot(aes(estimate, term)) +
    geom_point() +
    geom_errorbarh(aes(xmin = conf.low, xmax = conf.high))
```

```{r}
# model %>%
#   augment(data = wine_ratings) %>%
#   ggplot(aes(.fitted, points)) +
#     geom_point(alpha = .1)
# tidy(anova(model)) %>%
  # mutate(sumsq / sum(sumsq))
```

### Lasso regression on words in description

```{r}
library(tidytext)
wine_rating_words <- wine_ratings %>%
  mutate(wine_id = row_number()) %>%
  unnest_tokens(word, description) %>%
  anti_join(stop_words, by = "word") %>%
  filter(!word %in% c("wine", "drink"),
         str_detect(word, "[a-z]"))
wine_rating_words %>%
  count(word, sort = TRUE) %>%
  head(20) %>%
  mutate(word = fct_reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip()
```

```{r}
library(widyr)
wine_words_filtered <- wine_rating_words %>%
  distinct(wine_id, word) %>%
  add_count(word) %>%
  filter(n >= 100)
wine_words_filtered %>%
  pairwise_cor(word, wine_id, sort = TRUE)
```

```{r}
library(Matrix)
wine_word_matrix <- wine_words_filtered %>%
  cast_sparse(wine_id, word)
wine_ids <- as.integer(rownames(wine_word_matrix))
scores <- wine_ratings$points[wine_ids]
library(glmnet)
wine_word_matrix_extra <- cbind(wine_word_matrix, log_price = log2(wine_ratings$price[wine_ids]))
library(doMC)
registerDoMC(cores = 4)
cv_glmnet_model <- cv.glmnet(wine_word_matrix_extra, scores, parallel = TRUE)
plot(cv_glmnet_model)
```

```{r}
lexicon <- cv_glmnet_model$glmnet.fit %>%
  tidy() %>%
  filter(lambda == cv_glmnet_model$lambda.1se,
         term != "(Intercept)",
         term != "log_price") %>%
  select(word = term, coefficient = estimate)
lexicon %>%
  arrange(coefficient) %>%
  group_by(direction = ifelse(coefficient < 0, "Negative", "Positive")) %>%
  top_n(16, abs(coefficient)) %>%
  ungroup() %>%
  mutate(word = fct_reorder(word, coefficient)) %>%
  ggplot(aes(word, coefficient, fill = direction)) +
  geom_col() +
  coord_flip() +
  labs(x = "",
       y = "Estimated effect of the word on the score",
       title = "What words are predictive of a wine's score?")
```

```{r}
wine_ratings %>%
  mutate(wine_id = row_number()) %>%
  arrange(points) %>%
  head(1) %>%
  select(wine_id, description) %>%
  pull(description)
wine_rating_words %>%
  filter(wine_id %in% sample(unique(wine_id), 6)) %>%
  distinct(word, title, points) %>%
  mutate(wine = paste0(str_trunc(title, 40), " (", points, ")")) %>%
  inner_join(lexicon, by = "word") %>%
  mutate(word = fct_reorder(word, coefficient)) %>%
  ggplot(aes(word, coefficient, fill = coefficient > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~ wine, scales = "free_y") +
  labs(title = "How a lasso regression would predict each wine's score",
       subtitle = "Using a lasso regression with an extra term for price",
       x = "",
       y = "Effect on score")
```



### What is glmnet?

```{r}
cv_glmnet_model$glmnet.fit %>%
  tidy() %>%
  filter(term %in% c("rich", "black", "simple", "complex", "vineyard", "concentrated")) %>%
  ggplot(aes(lambda, estimate, color = term)) +
  geom_line() +
  scale_x_log10() +
  geom_hline(lty = 2, yintercept = 0)
cv_glmnet_model$glmnet.fit %>%
  tidy() %>%
  count(lambda) %>%
  ggplot(aes(lambda, n)) +
  geom_line() +
  scale_x_log10()
```


```{r}
wine_ratings %>%
  mutate(country = fct_relevel(fct_lump(country, 7), "US")) %>%
  mutate(country = fct_reorder(country, points)) %>%
  ggplot(aes(country, points)) +
  geom_boxplot() +
  coord_flip()
wine_ratings %>%
  group_by(year) %>%
  summarize(average_points = mean(points), n())
  
wine_ratings %>%
  mutate(reviewer = fct_reorder(fct_lump(taster_name, 10), points)) %>%
  ggplot(aes(reviewer, points)) +
  geom_boxplot() +
  coord_flip()
```



