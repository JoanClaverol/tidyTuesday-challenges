---
title: "TidyTuesday anlyses from David Robinson"
output: 
  html_document: 
    toc: true
    toc_float: true
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE,
                      cache = TRUE)
```

## Coffee ratings 

```{r}
# libraries
library(tidytuesdayR)
library(tidyverse)

# set plot theme
theme_set(theme_light())

# load data
coffee <- tt_load("2020-07-07")
coffee_ratings <- coffee$coffee_ratings %>%
  mutate(coffee_id = row_number()) %>%
  filter(total_cup_points > 0)
```

```{r}
coffee_ratings %>%
  count(species, sort = TRUE) # sort

# focus on variety, filter out any of it is missing
coffee_lumped <- coffee_ratings %>%
  filter(!is.na(variety)) %>%
  mutate(variety = fct_lump(variety, 12), # select the top 12 factors
         sort = TRUE)


coffee_lumped %>%
  mutate(
    variety = fct_reorder(
      variety, total_cup_points
      ) # reorder factors in relation to the total cup points
    ) %>% 
  ggplot(aes(total_cup_points, variety)) +
    geom_boxplot()


coffee_lumped %>%
  ggplot(aes(total_cup_points, fill = variety)) +
    geom_histogram(binwidth = 1) +
    facet_wrap(~ variety, scale = "free_y") + # adapt y axis to each variety
    theme(legend.position = "none")
```

```{r}

coffee_ratings %>%
  summarize(
    across(
      everything(), ~ mean(!is.na(.))
      )
    ) %>% 
  gather()

coffee_ratings %>%
  count(producer, sort = TRUE)
coffee_ratings %>%
  count(company, sort = TRUE)
coffee_ratings %>%
  count(color, sort = TRUE)


coffee_ratings %>%
  count(country = fct_lump(country_of_origin, 12), sort = TRUE) %>%
  filter(!is.na(country)) %>%
  mutate(country = fct_reorder(country, n)) %>%
  ggplot(aes(n, country)) +
  geom_col()


coffee_ratings %>%
  filter(!is.na(country_of_origin)) %>%
  mutate(country = fct_lump(country_of_origin, 12),
         country = fct_reorder(country, total_cup_points)) %>%
  ggplot(aes(total_cup_points, country)) +
  geom_boxplot()
```

Interesting dimensions:

* Country
* Variety
* Company??

```{r}
library(ggridges)
coffee_metrics <- coffee_ratings %>%
  select(coffee_id, total_cup_points, variety, company,
         country_of_origin,
         altitude_mean_meters,
         aroma:moisture) %>%
  pivot_longer(aroma:cupper_points, names_to = "metric", values_to = "value")
coffee_metrics %>%
  mutate(metric = fct_reorder(metric, value)) %>%
  ggplot(aes(value, metric)) +
  geom_density_ridges() # geom_density for categorical variables in a dataset
coffee_metrics %>%
  group_by(metric) %>%
  summarize(average = mean(value),
            sd = sd(value)) %>%
  arrange(desc(average))
```

```{r}
library(widyr) # finds correlation into a messy dataset
library(ggraph) # show network plot to find out clusters
library(igraph)
library(tidytext)
correlations <- coffee_metrics %>% 
  # do not understand that step
  pairwise_cor(item = metric, feature = coffee_id, value = value, sort = TRUE)


correlations %>%
  head(50) %>%
  # show clusters between correlated variables
  graph_from_data_frame() %>% 
  ggraph() +
    geom_edge_link(aes(edge_alpha = correlation)) +
    geom_node_point() +
    geom_node_text(aes(label = name), repel = TRUE)
```


```{r}
# time to apply a pca
coffee_metrics %>%
  filter(!metric %in% c("sweetness", "clean_cup", "uniformity")) %>%
  group_by(metric) %>%
  mutate(centered = value - mean(value)) %>% # center the values
  ungroup() %>%
  widely_svd(item = metric, feature = coffee_id, value = value) %>%
  filter(between(dimension, 2, 5)) %>%
  mutate(metric = reorder_within(metric, value, dimension)) %>%
  ggplot(aes(value, metric)) +
    geom_col() +
    scale_y_reordered() +
    facet_wrap(~ dimension, scales = "free_y")
```

```{r}
coffee_ratings %>%
  filter(altitude_mean_meters < 10000,
         altitude != 1) %>%
  mutate(altitude_mean_meters = pmin(altitude_mean_meters, 3000)) %>%
  ggplot(aes(altitude_mean_meters, total_cup_points)) +
    geom_point() +
    geom_smooth(method = "lm")
```


```{r}
coffee_metrics %>%
  filter(altitude_mean_meters < 10000) %>%
  mutate(altitude_mean_meters = pmin(altitude_mean_meters, 3000)) %>%
  mutate(km = altitude_mean_meters / 1000) %>%
  group_by(metric) %>%
  summarize(correlation = cor(altitude_mean_meters, value),
            model = list(lm(value ~ km))) %>%
  mutate(tidied = map(model, broom::tidy, conf.int = TRUE)) %>%
  unnest(tidied) %>%
  filter(term == "km") %>%
  ungroup() %>%
  mutate(metric = fct_reorder(metric, estimate)) %>%
  ggplot(aes(estimate, metric, color = p.value < .05)) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = .1) +
  labs(y = "Evaluation of coffee",
       x = "Each kilometer of altitude contributes this much to score (95% confidence interval)")
```

## Tour de France

```{r}
# libraries
library(tidytuesdayR)
library(tidyverse)
library(lubridate)
# set plot theme
theme_set(theme_light())
```


```{r}
tuesdata <- tidytuesdayR::tt_load('2020-04-07')
# look at the columns on the dataset
# let's analyse the birth winners
tdf_winners <- tuesdata$tdf_winners %>% 
  mutate(year = year(start_date), 
         speed = distance / time_overall)

stage_data <- tuesdata$stage_data
tdf_stages <- tuesdata$tdf_stages %>% 
  janitor::clean_names() %>% # put all the titles lower
  mutate(year = year(date))

# exploring winners data
tdf_winners %>% 
  count(birth_country, sort = TRUE) %>% 
  mutate(birth_country = fct_reorder(birth_country, n)) %>% 
  ggplot(aes(y = birth_country, x = n)) + 
    geom_col() + 
    labs(y = "", 
         title = "What the counties are the most Tour the France winners born in?")

tdf_winners %>% 
  count(winner_name, birth_country, sort = TRUE)
```

What has change over time? This question leads to how is the age disitributed over time? 

```{r}
tdf_winners %>% 
  group_by(decade = 10 * (year %/% 10)) %>% # truncated division to get the decade
  summarise(winner_age = mean(age), 
            winner_height = mean(height, na.rm = TRUE), 
            winner_weight = mean(weight, na.rm = TRUE)) %>% 
  ggplot(aes(x = decade, y = winner_age)) + 
    geom_line() + 
    expand_limits(y = 0)
```

There is no clear relation with age, weight or height over the year in the winners. 

Now he is looking at the time margin: 

```{r}
library(lubridate)
by_decade <- tdf_winners %>% 
  group_by(decade = 10 * (year %/% 10)) %>% # truncated division to get the decade
  summarise(winner_age = mean(age), 
            winner_height = mean(height, na.rm = TRUE), 
            winner_weight = mean(weight, na.rm = TRUE), 
            winner_margin = mean(time_margin, na.rm = TRUE), 
            winner_speed = mean(speed, na.rm = TRUE))

by_decade %>% 
  filter(decade >= 1910) %>% # there is only two data points in 1910 
  ggplot(aes(x = decade, y = winner_margin * 60)) + # transform to minutes
    geom_line() + 
    expand_limits(y = 0) + 
    labs(x = "Decade", 
         y = "Average margin of winner (minutes)", 
         title = "Tour the France has been getting closer")
```

This chart is meaningful. 

NOw let's look at the time of the winner: 

```{r}
by_decade %>%
  ggplot(aes(x = decade, y = winner_speed)) +
    geom_line() + 
    expand_limits(y = 0) + 
    labs(x = "Decade", 
         y = "Average speed of the winner (km/h)", 
         title = "Tour the France winners have been getting faster")
```

They have started to flatter on the paste year, possible doping?. 
TO know more abou it, I would be looking for some variable that affects the speed, like elevation. But they are on present on the dataset. 
So now we know with the winners dataset they are getting faster and there are getting closer (less margin time). 

Other things, average life expectancy of the winners. To do that, we will do a survivial analyses: 

```{r}
library(survival) # very good for medical proposals
library(broom)

surv_model <- tdf_winners %>% 
  distinct(winner_name, .keep_all = TRUE) %>% 
  transmute(winner_name,
            birth_year = year(born), 
            death_year = year(died), 
            dead = as.integer(!is.na(death_year))) %>% 
  mutate(age_at_death = coalesce(death_year, 2020) - birth_year) %>% # They are not death, we are just saying they are alive in 2020
  survival::survfit(Surv(age_at_death, dead) ~ 1, data = .) 

glance(surv_model)
```

Median life expectancy of a Tour of France winner is 77. 

Now let's start some exploration on the stage data: 

```{r}
# I want to join stage data, but I need to prepare them before doing it 
stages_joined <- stage_data %>% 
  extract(col = stage_results_id,
          into = "stage",
          regex = "stage-(.*)") %>%  # extract anything after "stage"
  inner_join(tdf_stages, by = c("year", "stage")) %>%  # I've lost a little bit of data
  mutate(rank = as.integer(rank)) %>% # NA introduced cause of people not finishing the race
 # add_count(year, stage, name = "competitors") # adding competitors by year and stage
  # now I want to get the number of finishers 
  group_by(year, stage) %>% 
  mutate(finishers = sum(!is.na(rank))) %>% 
  ungroup() %>% 
  mutate(percentile = 1 - rank / finishers)

stages_joined %>% 
  filter(stage == "1") %>% 
  group_by(winner_country) %>% 
  summarise(stages = n(), 
            median_percentile = median(percentile, na.rm = TRUE)) %>% 
  arrange(desc(stages))
```

This table tell us that no country does it better than the average at the first stage. 

How can I find the relation between the results at the first stage and how is affecting at the final results?
Does the winner of the first stage predict their final point ranking?

```{r}
total_points <- stages_joined %>% 
  group_by(year, rider) %>% 
  summarise(total_points = sum(points, na.rm = TRUE)) %>% 
  mutate(points_rank = percent_rank(total_points)) %>% 
  ungroup()

stages_joined %>% 
  filter(stage == "1") %>% 
  inner_join(total_points, by = c("year", "rider")) %>% 
  select(year, rider, percentile_first_stage = percentile, 
         points_rank) %>% 
  mutate(first_stage_bin = cut(percentile_first_stage, seq(0, 1, .1))) %>% 
  filter(!is.na(first_stage_bin)) %>% 
  ggplot(aes(y = first_stage_bin, x = points_rank)) + 
    geom_boxplot() + 
    labs(y = "Decile performance in the first stage", 
         x = "Overall points percentile")

```

So yes, there is a relation between your results at the first stage and the final results. 

Now we are going to use a gganimate to show a race: 

```{r}
library(gganimate)

top_10_2017 <- total_points %>% 
  filter(year == max(year)) %>% 
  top_n(10, total_points)

stages_joined %>% 
  filter(year == max(year)) %>% 
  semi_join(top_10_2017, by = "rider") %>% # now I have all the data for the top 10 riders accross all the time
  mutate(stage = as.integer(stage), 
         points = coalesce(points, 0)) %>% 
  group_by(rider) %>% 
  mutate(cumulative_points = cumsum(points)) %>% 
  ungroup() %>% 
  ggplot(aes(cumulative_points, rider, fill = cumulative_points)) + 
    geom_col() + 
    transition_time(stage) + 
    theme(legend.position = "none") + 
    labs(title = "The 2018 Tour France: Stage: {frame_time}", 
         x = "Cumulative points at this stage", 
         y = "") 
```

## The Office 

```{r}
library(tidyverse)
library(tidytuesdayR)
library(schrute)

# set plot theme
theme_set(theme_light())


office_data <- tt_load("2020-03-17")
office_ratings <- office_data$office_ratings  %>%
  mutate(name = str_to_lower(str_remove_all(title, "\\.| \\(Part.*|\\: Part.*")))

office_transcripts <- as_tibble(theoffice) %>% 
  mutate(season = as.integer(season),
         episode = as.integer(episode)) %>%
  mutate(character = str_remove_all(character, '"')) %>%
  mutate(name = str_to_lower(str_remove_all(episode_name, "\\.| \\(Part.*")))
```

```{r}
library(ggrepel)
office_ratings %>%
  group_by(season) %>%
  summarize(avg_rating = mean(imdb_rating)) %>%
  ggplot(aes(season, avg_rating)) +
    geom_line() +
    scale_x_continuous(breaks = 1:9)
```


```{r}
office_ratings %>%
  mutate(title = fct_inorder(title),
         episode_number = row_number()) %>%
  ggplot(aes(episode_number, imdb_rating)) +
    geom_line() +
    geom_smooth() +
    geom_point(aes(color = factor(season), size = total_votes)) +
    geom_text(aes(label = title), check_overlap = TRUE, hjust = 1) +
    expand_limits(x = -10) +
    theme(panel.grid.major.x = element_blank(),
          legend.position = "none") +
    labs(x = "Episode number",
         y = "IMDB Rating",
         title = "Popularity of The Office episodes over time",
         subtitle = "Color represents season, size represents # of ratings")
```

```{r}
office_ratings %>%
  arrange(desc(imdb_rating)) %>%
  mutate(title = paste0(season, ".", episode, " ", title),
         title = fct_reorder(title, imdb_rating)) %>%
  head(20) %>%
  ggplot(aes(title, imdb_rating, color = factor(season), size = total_votes)) +
  geom_point() +
  coord_flip() +
  labs(color = "Season",
       title = "Most popular episodes of The Office")
```

### Transcripts

```{r}
library(tidytext)
blacklist <- c("yeah", "hey", "uh", "gonna")
blacklist_characters <- c("Everyone", "All", "Both", "Guy", "Girl", "Group")
transcript_words <- office_transcripts %>%
  group_by(character) %>%
  filter(n() >= 100,
         n_distinct(episode_name) > 2) %>%
  ungroup() %>%
  select(-text_w_direction) %>%
  unnest_tokens(word, text) %>% 
  anti_join(stop_words, by = "word") %>%
  filter(!word %in% blacklist,
         !character %in% blacklist_characters)
```


```{r}
character_tf_idf <- transcript_words %>%
  add_count(word) %>%
  filter(n >= 20) %>%
  count(word, character) %>%
  # which words are more specific to each character
  bind_tf_idf(word, character, n) %>%
  arrange(desc(tf_idf))
```

```{r}
character_tf_idf %>%
  filter(character %in% c("Dwight", "Jim", "David Wallace", "Darryl", "Jan", "Holly")) %>%
  group_by(character) %>%
  top_n(10, tf_idf) %>%
  ungroup() %>%
  mutate(word = reorder_within(word, tf_idf, character)) %>%
  ggplot(aes(word, tf_idf)) +
    geom_col() +
    coord_flip() +
    scale_x_reordered() +
    facet_wrap(~ character, scales = "free_y") +
    labs(x = "",
         y = "TF-IDF of character-word pairs")
```

```{r}
office_transcripts %>%
  count(character, sort = TRUE) %>%
  filter(character == "Dwight")
```

### Machine learning model

What affects popularity of an episode:

* Season/time
* Director
* Writer
* Lines per character

```{r}
ratings_summarized <- office_ratings %>%
  group_by(name) %>%
  summarize(imdb_rating = mean(imdb_rating))
character_lines_ratings <- office_transcripts %>%
  filter(!character %in% blacklist_characters) %>%
  count(character, name) %>%
  group_by(character) %>%
  filter(sum(n) >= 50,
         n() >= 5) %>%
  inner_join(ratings_summarized, by = "name")
character_lines_ratings %>%
  summarize(avg_rating = mean(imdb_rating),
            nb_episodes = n()) %>%
  arrange(desc(avg_rating))
```



```{r}
director_writer_features <- office_transcripts %>%
  distinct(name, director, writer) %>%
  gather(type, value, director, writer) %>%
  separate_rows(value, sep = ";") %>%
  unite(feature, type, value, sep = ": ") %>%
  group_by(feature) %>%
  filter(n() >= 3) %>%
  mutate(value = 1) %>%
  ungroup()

character_line_features <- character_lines_ratings %>%
  ungroup() %>%
  transmute(name, feature = character, value = log2(n))
season_features = office_ratings %>%
  distinct(name, season) %>%
  transmute(name, feature = paste("season:", season), value = 1)
features <- bind_rows(director_writer_features,
                      character_line_features,
                      season_features) %>%
  semi_join(office_ratings, by = "name") %>%
  semi_join(office_transcripts, by = "name")
```

```{r}
episode_feature_matrix <- features %>%
  cast_sparse(name, feature, value)
ratings <- ratings_summarized$imdb_rating[match(rownames(episode_feature_matrix), ratings_summarized$name)]
```

```{r}
library(glmnet)
library(broom)
mod <- cv.glmnet(episode_feature_matrix, ratings)
plot(mod)
```


```{r}
tidy(mod$glmnet.fit) %>%
  filter(lambda == mod$lambda.min,
         term != "(Intercept)") %>%
  mutate(term = fct_reorder(term, estimate)) %>%
  ggplot(aes(term, estimate, fill = estimate > 0)) +
  geom_col() +
  coord_flip() +
  labs(y = "Estimated effect on the rating of an episode") +
  theme(legend.position = "none")
```

## Wine ratings

```{r}
library(tidyverse)
library(tidytuesdayR)

theme_set(theme_light())

# load and cleaning step
wine_ratings <- tt_load("2019-05-28")$`winemag-data-130k-v2` %>%
  select(-X1) %>%
  # extract 4 digitis which starts with 20, in a new column called year, 
  extract(title, "year", "(20\\d\\d)", convert = TRUE, remove = FALSE) %>%
  mutate(year = ifelse(year < 1900, NA, year)) %>%
  filter(!is.na(price))
```

```{r}
wine_ratings %>%
  count(country, sort = T)
```


```{r}
wine_ratings %>%
  count(designation, sort = T)
```


```{r}
wine_ratings %>%
  count(country, region_1, sort = TRUE)
```


```{r}
wine_ratings %>%
  count(taster_name, sort = TRUE)
```


```{r}
wine_ratings %>%
  filter(!is.na(designation)) %>%
  count(variety, designation, sort = TRUE)
```


```{r}
wine_ratings %>%
  ggplot(aes(year)) +
  geom_histogram()
```


```{r}
wine_ratings %>%
  ggplot(aes(points)) +
  geom_histogram(binwidth = 1)
```


```{r}
wine_ratings %>%
  ggplot(aes(price)) +
  geom_histogram() +
  # us a log scale to see if iti is a normal distribution
  scale_x_log10()
```

```{r}
ggplot(wine_ratings, aes(price, points)) +
  geom_point(alpha = .1) +
  geom_smooth(method = "lm") +
  scale_x_log10()
# predict the points by the price of a wine
summary(lm(points ~ log2(price), wine_ratings))
```

Every time the price doubles, the expected number of points goes up by 2.

```{r}
library(broom)
model <- wine_ratings %>%
  replace_na(list(taster_name = "Missing", country = "Missing")) %>%
  mutate(country = fct_relevel(fct_lump(country, 7), "US"),
         taster_name = fct_relevel(fct_lump(taster_name, 6), "Missing")) %>%
  lm(points ~ log2(price) + country + year + taster_name, data = .)

model %>%
  tidy(conf.int = TRUE) %>%
  filter(term != "(Intercept)") %>%
  mutate(term = str_replace(term, "country", "Country: "),
         term = str_replace(term, "taster_name", "Taster: "),
         term = fct_reorder(term, estimate)) %>%
  ggplot(aes(estimate, term)) +
    geom_point() +
    geom_errorbarh(aes(xmin = conf.low, xmax = conf.high))
```

```{r}
# model %>%
#   augment(data = wine_ratings) %>%
#   ggplot(aes(.fitted, points)) +
#     geom_point(alpha = .1)
# tidy(anova(model)) %>%
  # mutate(sumsq / sum(sumsq))
```

### Lasso regression on words in description

```{r}
library(tidytext)
wine_rating_words <- wine_ratings %>%
  mutate(wine_id = row_number()) %>%
  unnest_tokens(word, description) %>%
  anti_join(stop_words, by = "word") %>%
  filter(!word %in% c("wine", "drink"),
         str_detect(word, "[a-z]"))
wine_rating_words %>%
  count(word, sort = TRUE) %>%
  head(20) %>%
  mutate(word = fct_reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip()
```

```{r}
library(widyr)
wine_words_filtered <- wine_rating_words %>%
  distinct(wine_id, word) %>%
  add_count(word) %>%
  filter(n >= 100)
wine_words_filtered %>%
  pairwise_cor(word, wine_id, sort = TRUE)
```

```{r}
library(Matrix)
wine_word_matrix <- wine_words_filtered %>%
  cast_sparse(wine_id, word)
wine_ids <- as.integer(rownames(wine_word_matrix))
scores <- wine_ratings$points[wine_ids]
library(glmnet)
wine_word_matrix_extra <- cbind(wine_word_matrix, log_price = log2(wine_ratings$price[wine_ids]))
library(doMC)
registerDoMC(cores = 4)
cv_glmnet_model <- cv.glmnet(wine_word_matrix_extra, scores, parallel = TRUE)
plot(cv_glmnet_model)
```

```{r}
lexicon <- cv_glmnet_model$glmnet.fit %>%
  tidy() %>%
  filter(lambda == cv_glmnet_model$lambda.1se,
         term != "(Intercept)",
         term != "log_price") %>%
  select(word = term, coefficient = estimate)
lexicon %>%
  arrange(coefficient) %>%
  group_by(direction = ifelse(coefficient < 0, "Negative", "Positive")) %>%
  top_n(16, abs(coefficient)) %>%
  ungroup() %>%
  mutate(word = fct_reorder(word, coefficient)) %>%
  ggplot(aes(word, coefficient, fill = direction)) +
  geom_col() +
  coord_flip() +
  labs(x = "",
       y = "Estimated effect of the word on the score",
       title = "What words are predictive of a wine's score?")
```

```{r}
wine_ratings %>%
  mutate(wine_id = row_number()) %>%
  arrange(points) %>%
  head(1) %>%
  select(wine_id, description) %>%
  pull(description)
wine_rating_words %>%
  filter(wine_id %in% sample(unique(wine_id), 6)) %>%
  distinct(word, title, points) %>%
  mutate(wine = paste0(str_trunc(title, 40), " (", points, ")")) %>%
  inner_join(lexicon, by = "word") %>%
  mutate(word = fct_reorder(word, coefficient)) %>%
  ggplot(aes(word, coefficient, fill = coefficient > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~ wine, scales = "free_y") +
  labs(title = "How a lasso regression would predict each wine's score",
       subtitle = "Using a lasso regression with an extra term for price",
       x = "",
       y = "Effect on score")
```



### What is glmnet?

```{r}
cv_glmnet_model$glmnet.fit %>%
  tidy() %>%
  filter(term %in% c("rich", "black", "simple", "complex", "vineyard", "concentrated")) %>%
  ggplot(aes(lambda, estimate, color = term)) +
  geom_line() +
  scale_x_log10() +
  geom_hline(lty = 2, yintercept = 0)
cv_glmnet_model$glmnet.fit %>%
  tidy() %>%
  count(lambda) %>%
  ggplot(aes(lambda, n)) +
  geom_line() +
  scale_x_log10()
```


```{r}
wine_ratings %>%
  mutate(country = fct_relevel(fct_lump(country, 7), "US")) %>%
  mutate(country = fct_reorder(country, points)) %>%
  ggplot(aes(country, points)) +
  geom_boxplot() +
  coord_flip()
wine_ratings %>%
  group_by(year) %>%
  summarize(average_points = mean(points), n())
  
wine_ratings %>%
  mutate(reviewer = fct_reorder(fct_lump(taster_name, 10), points)) %>%
  ggplot(aes(reviewer, points)) +
  geom_boxplot() +
  coord_flip()
```

## NCAA Women's Basketball Tournament

```{r}
library(tidyverse)
library(tidytuesdayR)
library(scales)

theme_set(theme_light())

tt <- tt_load("2020-10-06") 

finish_levels <- c("1st", "2nd", "RSF", "RF", "NSF", "N2nd", "Champ")

tournament <- tt$tournament %>% 
  filter(year >= 1994) %>% 
  mutate(tourney_finish = fct_relevel(tourney_finish, finish_levels))
```

How many teams has been since the first date in the dataset: 

```{r}
tt$tournament %>% 
  count(year) %>% 
  ggplot(aes(year, n)) + 
    geom_col()
```

There has veen 64 teams. 

How many schoold had been?
```{r}
tt$tournament %>% 
  count(school, sort = TRUE)
```

Placement is really interesting: 

```{r}
tt$tournament %>% 
  count(conf_place, sort = TRUE)
```

There are problems on data quality. String do not make sense. Need to change that. 

Let's also chekck some other data quality. 

```{r}
tournament %>% 
  ggplot(aes(full_w, tourney_w + reg_w)) + 
    geom_point(alpha = .1)
```
Understainding the data: 

* Regular wins are before the tournament
* Conf wins are subset of regular wins
* Tournament wins are in this bracket of 64

There have been 64 temas since 1964. 

```{r}
by_seed <- tournament %>% 
  group_by(seed) %>% 
  summarise(
    n = n(), 
    pct_win = mean(tourney_finish == "Champ"), 
    pct_final_four = mean(tourney_finish %in% c("Champ", "N2nd","NSF")),
    avg_round = mean(as.integer(tourney_finish))
  )
by_seed
```


```{r}
by_seed %>% 
  ggplot(aes(seed, avg_round)) + 
  geom_line() + 
  labs(x = "Starting seed", 
       y = "On average, elminitaed in round...")
```


```{r}
by_seed %>% 
  ggplot(aes(seed, pct_final_four)) + 
  geom_line() + 
  scale_y_continuous(labels = percent) + 
  labs(x = "Starting seed", 
       y = "% of tims making the Final Four")
```


```{r}
tournament %>% 
  count(seed, tourney_finish) %>% 
  group_by(seed) %>% 
  mutate(pct = n / sum(n)) %>% 
  ggplot(aes(tourney_finish, seed, fill = pct)) + 
  geom_tile() +
  geom_text(aes(label = percent(pct, accuracy = 1))) + 
  scale_x_discrete(expand = c(0,0)) + 
  scale_y_reverse(breaks = seq(1, 16), expand = c(0, 0)) + 
  scale_fill_gradient2(high = "blue", labels = percent) + 
  theme(panel.grid =element_blank(), 
        axis.ticks = element_blank()) +
  labs(x = "tournament finish (worst to best)", 
       y = "starting seed", 
       fill = "% of seed", 
       title = "When a team starts in a seed, how do they end up?")
```

Has teh correlation of seededness to # of rounds changed over time?

```{r}
tournament %>% 
  ggplot(aes(seed, as.integer(tourney_finish))) + 
  geom_point(alpha = .1)
# there is a negative correlation


tournament %>% 
  group_by(year) %>% 
  summarise(correlation = cor(seed, as.integer(tourney_finish))) %>% 
  ggplot(aes(year, correlation)) + 
  geom_line()
```

No, the predecitiviness of a seed hasn't changed in 24 year. 

Predicitng seed + outcome from regular season / conference

```{r}
tournament %>% 
  ggplot(aes(seed, reg_percent)) +
  geom_boxplot(aes(group = seed)) + 
  geom_smooth(method = "loess")
```

Why the teams on seed 12 do better than 10

Is it different by the region/

```{r}
tournament %>% 
  mutate(conference = fct_lump(conference, 5)) %>% 
  ggplot(aes(seed, reg_percent)) +
  # geom_boxplot(aes(group = seed)) + 
  geom_point(width = .05) + 
  geom_smooth(method = "loess") + 
  facet_wrap(~ conference)
```

There are some conference who never get placed over the 12 seed. 

```{r}
tournament %>% 
  ggplot(aes(reg_percent, as.integer(tourney_w))) + 
  geom_point() + 
  geom_smooth(method = "lm") +
  facet_wrap(~ seed)

tournament %>% 
  group_by(seed) %>% 
  summarise(correlation = )
```


## Great american Beer Festival

```{r}
library(tidyverse)
library(tidytuesdayR)
library(glue)

theme_set(theme_light())
```

```{r}
tt <- tidytuesdayR::tt_load("2020-10-20")
```

```{r}
beer_awards <- tt$beer_awards %>% 
  mutate(state = str_to_upper(state), 
         medal = fct_relevel(medal, c("Bronze", "Silver", "Gold")))

beer_awards %>% 
  count(year) %>% 
  ggplot(aes(year, n)) + 
  geom_col()
```

Increasing number of cities: 

```{r}
beer_awards %>% 
  count(city, state, sort = T)
```

```{r}
beer_awards %>% 
  count(state, sort = T)
```

```{r}
beer_awards %>% 
  count(brewery, city, state, sort = T)
```

```{r}
beer_awards %>% 
  count(category, sort = T)
```

```{r}
beer_awards %>% 
  filter(category == "Bock")
```

Whihc are th emost awarded beers?

```{r}
beer_counts <- beer_awards %>% 
  count(beer_name, brewery, medal, city, state)

beer_counts %>% 
  mutate(beer_name = glue("{ beer_name } ({ brewery })")) %>% 
  filter(fct_lump(beer_name, 16, w = n) != "Other") %>% 
  mutate(beer_name = fct_reorder(beer_name, n, sum)) %>% 
  ggplot(aes(n, beer_name, fill = medal)) + 
  geom_col() + 
  labs(title = "Which beers have won th emost awards?", 
       x = "# of awards", 
       y = "")


beer_counts %>% 
  pivot_wider(names_from = medal, values_from = n, 
              values_fill = list(n = 0)) %>% 
  mutate(total = Bronze + Silver + Gold) %>% 
  arrange(desc(total))
```

Let's look at the states

 *Which states have won the most?

```{r}
beer_awards %>% 
  count(state, sort=T)
```

Whihc is the state missing?

```{r}
setdiff(state.abb, beer_awards$state)
```

Miss represtnation with states: 

* Choreplot ( colored map ) 
* Per capita award winning beers
* Put dots for cities + breweries 

What breweries won the most awards

```{r}
by_brewery <- beer_awards %>% 
  group_by(brewery) %>% 
  summarise(n_medals = n(), 
            n_beers = n_distinct(beer_name), 
            weighted_ls = (sum(as.integer(medal)))) %>% 
  arrange(desc(n_medals))

beer_awards %>% 
  count(brewery, medal) %>% 
  filter(fct_lump(brewery, 16, w = n) != "Other") %>% 
  mutate(brewery = fct_reorder(brewery, n, sum)) %>% 
  ggplot(aes(n, brewery, fill = medal)) + 
  geom_col() + 
  labs(title = "Which brewery have won th emost awards?", 
       x = "# of awards", 
       y = "")
```

Look awards per capitaL 

```{r}
beer_awards %>% 
  count(state, medal) %>% 
  filter(fct_lump(state, 16, w = n) != "Other") %>% 
  mutate(state = fct_reorder(state, n, sum)) %>% 
  ggplot(aes(n, state, fill = medal)) + 
  geom_col() + 
  labs(title = "Which state have won th emost awards?", 
       x = "# of awards", 
       y = "")
```

Underepresented categories: 

```{r}
library(tidylo)
library(tidytext)

beer_awards %>% 
  filter(fct_lump(state, 9) != "Other", 
         fct_lump(category, 9) != "Other") %>% 
  count(state, category) %>% 
  complete(state, category, fill = list(n = 0)) %>% 
  bind_log_odds(state, category, n) %>% 
  mutate(state = fct_reorder(state, -n, sum)) %>% 
  mutate(category = reorder_within(category, log_odds_weighted, state)) %>% 
  ggplot(aes(log_odds_weighted, category, fill = log_odds_weighted > 0)) + 
  geom_col() + 
  scale_y_reordered() + 
  facet_wrap(~state, scales = "free_y") + 
  theme(legend.position = "none") + 
  labs(x = "Weighted log-odds", 
       y = "Category", 
       title = "What types of beer are over - or under - represented in awards each state?", 
       subtitle = "For the 9 states with the most awards")
```

States

```{r}
by_year_state <- beer_awards %>%
  add_count(year, name = "year_total") %>%
  mutate(state = fct_lump(state, 9)) %>%
  count(year, state, year_total, sort = TRUE) %>%
  mutate(pct_year = n / year_total)
by_year_state %>%
  filter(state != "Other") %>%
  ggplot(aes(year, pct_year, color = state)) +
  geom_line() +
  expand_limits(y = 0) +
  scale_y_continuous(labels = percent) +
  facet_wrap(~ state)
by_year_state %>%
  filter(state == "WI") %>%
  glm(cbind(n, year_total - n) ~ year,
      data = .,
      family = "binomial") %>%
  summary()
library(broom)
by_year_state %>%
  filter(state != "Other") %>%
  mutate(state = state.name[match(state, state.abb)]) %>%
  group_by(state) %>%
  summarize(model = list(glm(cbind(n, year_total - n) ~ year, family = "binomial"))) %>%
  mutate(tidied = map(model, tidy, conf.int = TRUE)) %>%
  unnest(tidied) %>%
  filter(term == "year") %>%
  mutate(p.value = format.pval(p.value),
         state = fct_reorder(state, estimate)) %>%
  ggplot(aes(estimate, state)) +
  geom_point() +
  geom_vline(xintercept = 0, lty = 2) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = .1) +
  labs(x = "Estimated slope",
       title = "Which states become more or less frequent medal winners?",
       y = "")
```


```{r}
library(ggthemes)
map_data("state")
beer_awards %>%
  mutate(state = str_to_lower(state.name[match(state, state.abb)])) %>%
  count(state) %>%
  right_join(map_data("state"), by = c(state = "region")) %>%
  ggplot(aes(long, lat, fill = n, group = group)) +
  geom_polygon() +
  theme_map() +
  coord_map() +
  labs(fill = "# of award-winning beers")
```

